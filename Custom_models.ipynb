{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(housing.data,\n",
    "                                                           housing.target.reshape(-1,1),random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scalled = scaler.fit_transform(X_train)\n",
    "X_valid_scalled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.477  ],\n",
       "       [0.458  ],\n",
       "       [5.00001],\n",
       "       ...,\n",
       "       [1.177  ],\n",
       "       [2.631  ],\n",
       "       [4.815  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true,y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) <1\n",
    "    squared_loss = tf.square(error) /2 \n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error,squared_loss,linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure huber_loss.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,3.5))\n",
    "z = np.linspace(-4,4,200)\n",
    "plt.plot(z,huber_fn(0,z),\"b-\",linewidth=2,label=\"huber($z$\")\n",
    "plt.plot(z,z**2 / 2, \"b:\",linewidth=1,label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "save_fig(\"huber_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:] # 8\n",
    "model_1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation=\"selu\",kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=huber_fn,optimizer=\"nadam\",metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 8.6957 - mse: 192.5037 - val_loss: 6.5935 - val_mse: 127.4433\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.7416 - mse: 32.5135 - val_loss: 1.3268 - val_mse: 11.2970\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.8515 - mse: 20.1265 - val_loss: 2.4982 - val_mse: 14.4796\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.4720 - mse: 15.2569 - val_loss: 3.1037 - val_mse: 25.3131\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.2153 - mse: 12.7074 - val_loss: 2.1445 - val_mse: 13.3448\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0034 - mse: 10.7746 - val_loss: 1.1794 - val_mse: 6.6127\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8736 - mse: 9.7841 - val_loss: 0.9633 - val_mse: 6.0810\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7761 - mse: 9.0473 - val_loss: 1.1394 - val_mse: 19.2476\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7509 - mse: 8.6714 - val_loss: 2.4548 - val_mse: 23.2066\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5719 - mse: 7.4211 - val_loss: 1.5609 - val_mse: 24.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab69bfb80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train,y_train,epochs=10,validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving / Loading models with custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the custome model\n",
    "model_1.save(\"model_1_with_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_load = keras.models.load_model(\"model_1_with_custom_loss.h5\",\n",
    "                                       custom_objects={\"huber_fn\":huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3646 - mse: 1.3827 - val_loss: 0.4038 - val_mse: 37.2830\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2558 - mse: 0.9243 - val_loss: 0.3639 - val_mse: 32.4104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab59bf310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_load.fit(X_train_scalled,y_train,epochs=2,\n",
    "                 validation_data=[X_valid_scalled,y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the hubber function with the spesific theresold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(thereshold=1.0):\n",
    "    def huber_fn(y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < thereshold\n",
    "        squared_loss = tf.square(error) /2\n",
    "        linear_loss = thereshold * tf.abs(error) - thereshold ** 2 / 2\n",
    "        return tf.where(is_small_error,squared_loss,linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom object (theresold isnt save on save models) must be eksplisit on the load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model_2 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss=create_huber(2.0),optimizer=\"nadam\",metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8424 - mae: 0.9687 - val_loss: 0.2742 - val_mae: 0.5242\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2394 - mae: 0.5101 - val_loss: 0.2210 - val_mae: 0.4915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab5ae0850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train_scalled,y_train,epochs=2,\n",
    "            validation_data=[X_valid_scalled,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"model_2_with_custom_loss_thershold.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.models.load_model(\"model_2_with_custom_loss_thershold.h5\",\n",
    "                                  custom_objects={\"huber_fn\":create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untuk menghindari custom objects by parameter bisa digunakan class dengan ditambahkan get config dari parent class keras.losses.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self,threshold=1.0,**kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self,y_true,y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config=super().get_config()\n",
    "        return {**base_config,\"threshold\":self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(loss=HuberLoss(2.0),optimizer=\"nadam\",\n",
    "                metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7663 - mae: 0.9262 - val_loss: 124.5908 - val_mae: 63.2846\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2432 - mae: 0.5180 - val_loss: 74.7052 - val_mae: 38.3378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab5c3c970>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train_scalled,y_train,epochs=2,\n",
    "            validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save(\"model_3_with_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = keras.models.load_model(\"model_3_with_custom_loss_class.h5\",\n",
    "                                  custom_objects={\"HuberLoss\":HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2283 - mae: 0.5015 - val_loss: 60.1808 - val_mae: 31.0787\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2219 - mae: 0.4922 - val_loss: 71.8824 - val_mae: 36.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab5d57130>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train_scalled,y_train,epochs=2,\n",
    "            validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1,activation=my_softplus,\n",
    "                           kernel_initializer = my_glorot_initializer,\n",
    "                           kernel_regularizer= my_l1_regularizer,\n",
    "                           kernel_constraint = my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0125 - mae: 1.0132 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6258 - mae: 0.5279 - val_loss: 2.8053 - val_mae: 0.5339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aaac4bfdf0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(X_train_scalled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scalled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = keras.models.load_model(\"my_model_with_many_custom_parts.h5\",\n",
    "                                  custom_objects={\n",
    "                                        \"my_l1_regularizer\": my_l1_regularizer,\n",
    "                                        \"my_positive_weights\": my_positive_weights,\n",
    "                                        \"my_glorot_initializer\": my_glorot_initializer,\n",
    "                                        \"my_softplus\": my_softplus,\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self,weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\":self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4313 - mae: 0.8508 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6202 - mae: 0.5163 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab5eedee0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(X_train_scalled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scalled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 798us/step - loss: 1.8960 - huber_fn: 0.8000\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.5667 - huber_fn: 0.2433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab611ec40>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit(X_train_scalled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 855us/step - loss: 0.1146 - huber_fn: 0.2317\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.1109 - huber_fn: 0.2245\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model_6.fit(X_train_scalled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stremming metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_state() # rest state on variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating streaming metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check hubermetric class work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 764us/step - loss: 0.7861 - huber_metric: 0.7861\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.2469 - huber_metric: 0.2469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab63befa0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(X_train_scalled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 812us/step - loss: 0.2303 - huber_metric: 0.2303\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.2213 - huber_metric: 0.2213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab652eca0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(X_train_scalled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huberclass can from lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 851us/step - loss: 0.3713 - HuberMetric: 0.7481\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.1215 - HuberMetric: 0.2449\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model_8.fit(X_train_scalled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37126243114471436, 0.37126253083440175)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8 = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",\n",
    "                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 826us/step - loss: 0.2335 - HuberMetric: 0.2335\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.2263 - HuberMetric: 0.2263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab6603e50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.fit(X_train_scalled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custome layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to create the custom layer can be wrap to lambda functional on the function set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x : tf.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1.,0.,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very deifferent scales (1e-3,1e1,1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation=\"relu\",input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8132 - val_loss: 0.4472\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4200 - val_loss: 0.3663\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3891 - val_loss: 0.3465\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3798 - val_loss: 0.3470\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.3666 - val_loss: 0.3485\n",
      "162/162 [==============================] - 0s 733us/step - loss: 0.3603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36026594042778015"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.compile(loss=\"mse\",optimizer=\"sgd\")\n",
    "model_9.fit(X_train_scalled,y_train,epochs=5,\n",
    "            validation_data= [X_valid_scalled,y_valid])\n",
    "model_9.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom the dense layers\n",
    "class MyDense(keras.layers.Layer):\n",
    "    #initialiation hyperparameter thershold\n",
    "    def __init__(self,units,activation=None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    \n",
    "    # create the arsitecture kernel(weights neuron connection) & bias\n",
    "    def build(self,batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",shape=[batch_input_shape[-1],self.units],\n",
    "            initializer=\"glorot_normal\"\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\",shape=[self.units],\n",
    "            initializer=\"zeros\"\n",
    "        ) \n",
    "        #to be know the arsitecture has been created\n",
    "        super().build(batch_input_shape)\n",
    "    # forward pass\n",
    "    def call(self,X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    # output shape -> input shape to next layer\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.bias])\n",
    "    \n",
    "    # config the theresold must be saved on classes\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config,\"units\":self.units,\n",
    "                \"activation\":keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = keras.models.Sequential([\n",
    "    MyDense(30,activation=\"relu\",input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4899 - val_loss: 2.1341\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6141 - val_loss: 0.8687\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4856 - val_loss: 0.5723\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.4328 - val_loss: 0.4590\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.4114 - val_loss: 0.4015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab6912b20>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.compile(loss=\"mse\",optimizer=\"nadam\")\n",
    "model_10.fit(X_train_scalled,y_train,epochs=5,\n",
    "             validation_data=[X_valid_scalled,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10.save(\"model_with_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = keras.models.load_model(\"model_with_custom_layer.h5\",\n",
    "                                   custom_objects={\"MyDense\":MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3976 - val_loss: 0.4038\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3899 - val_loss: 0.5690\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3846 - val_loss: 0.3629\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3568\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab6a90b20>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.fit(X_train_scalled,y_train,epochs=5,\n",
    "             validation_data=[X_valid_scalled,y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custome layer with multiple_inputs or multiple_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs and 3 outputs\n",
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self,X):\n",
    "        X1,X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape)\n",
    "        return X1 + X2, X1 * X2,X1 / X2\n",
    "    \n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        batch_input_shape1,batch_input_shape2,batch_input_shape3 = batch_input_shape\n",
    "        return [batch_input_shape1,batch_input_shape2,batch_input_shape3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 3)  X2.shape:  (None, 3)\n"
     ]
    }
   ],
   "source": [
    "# Multiple input cant handle with sequential models (only 1 inputs and 1 outputs)\n",
    "\n",
    "inputs1 = keras.layers.Input(shape=[3])\n",
    "inputs2 = keras.layers.Input(shape=[3])\n",
    "outpus1,outputs2,outputs3 = MyMultiLayer()((inputs1,inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, whose shape is only partially specified (at this stage, we don't know the batch size, which is why the first dimension is `None`):\n",
    "\n",
    "We can also pass actual data to the custom layer. To test this, let's split each dataset's inputs into two parts, with four features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count //2\n",
    "    return data[:,:half], data[:,half:]\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scalled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scalled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "outputs1, outputs2,outputs3 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.17324547 -1.6507294  -0.01412493 -1.4073021 ]\n",
      " [ 2.6134481  -1.6637297  -0.5110694   0.86339283]\n",
      " [-0.5025582  -0.27013135  2.1268167  -0.6402433 ]\n",
      " ...\n",
      " [-0.7709261   0.6388412  -1.2357894   1.4055338 ]\n",
      " [-0.9933209   1.8356445   0.41289914 -0.16435926]\n",
      " [ 0.7240328   0.00968345  1.4208122  -1.4639156 ]], shape=(11610, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.00402183  0.61749667 -0.8766508  -0.02112347]\n",
      " [ 1.3997903  -0.38343248 -0.37163973 -0.2558276 ]\n",
      " [ 0.03643769 -0.00890543  1.0706553  -1.7933904 ]\n",
      " ...\n",
      " [-0.5534281   0.0678305   0.371412    0.29685235]\n",
      " [ 0.05403009 -0.02504723 -0.0567511   0.0063295 ]\n",
      " [-0.15393297 -0.03349337  0.3358127   0.2048483 ]], shape=(11610, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-9.3558846e+00  1.8812752e+00 -1.0152001e+00 -1.0444104e-02]\n",
      " [ 4.0397388e-01 -9.1092148e+00 -4.4239715e-01 -2.1271384e-01]\n",
      " [ 4.7195277e+00 -9.9059708e-02  6.2510151e-01 -6.2272650e-01]\n",
      " ...\n",
      " [-2.7040911e+00  3.7500737e+00  7.1688426e-01  2.2577792e-01]\n",
      " [ 1.6200068e+01 -1.3652214e+02 -2.0852582e-01  5.9928054e-01]\n",
      " [-5.2137299e+00 -1.0543299e+00  2.6706985e-01  1.1987880e-01]], shape=(11610, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs1)\n",
    "print(outputs2)\n",
    "print(outputs3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build more complete model using the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B,hidden_C = MyMultiLayer()((input_A,input_B))\n",
    "\n",
    "hidden_A = keras.layers.Dense(30,activation=\"selu\")(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30,activation=\"selu\")(hidden_B)\n",
    "hidden_C = keras.layers.Dense(30,activation = \"selu\")(hidden_C)\n",
    "concat = keras.layers.Concatenate()((hidden_A,hidden_B,hidden_C))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model_11 = keras.models.Model(inputs=[input_A,input_B],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "327/363 [==========================>...] - ETA: 0s - loss: 119.6101X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 238.2614 - val_loss: 64.1189\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 17.5969 - val_loss: 10.4930\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3888 - val_loss: 4.3007\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2202 - val_loss: 1.3437\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.4090 - val_loss: 58.6377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aabfab0820>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=5,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create layer with different behavior during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self,stddev,**kwargs) :\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    \n",
    "    def call(self,X,training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X),stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else :\n",
    "            return X\n",
    "    def compute_output_shape(self,batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_12 = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.4826 - val_loss: 8.1577\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0973 - val_loss: 5.4373\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0629 - val_loss: 3.4268\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0405 - val_loss: 2.1728\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 997us/step - loss: 1.0071 - val_loss: 1.4725\n",
      "162/162 [==============================] - 0s 673us/step - loss: 0.8205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8204621076583862"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model_12.fit(X_train_scalled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scalled, y_valid))\n",
    "model_12.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range (1+3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self,n_layers,n_neurons,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons,activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30,activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2,30)\n",
    "        self.block2 = ResidualBlock(2,30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1+3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 1ms/step - loss: 12.9798\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.9566\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7793\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6661\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6288\n",
      "162/162 [==============================] - 0s 826us/step - loss: 0.5633\n",
      "162/162 [==============================] - 0s 770us/step\n"
     ]
    }
   ],
   "source": [
    "model_13 = ResidualRegressor(1)\n",
    "model_13.compile(loss=\"mse\",optimizer=\"nadam\")\n",
    "history_13 = model_13.fit(X_train_scalled,y_train,epochs=5)\n",
    "score = model_13.evaluate(X_test_scaled,y_test)\n",
    "y_pred = model_13.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n"
     ]
    }
   ],
   "source": [
    "model_13.save(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_13 = keras.models.load_model(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4746\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9560\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6148\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3728\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5478\n"
     ]
    }
   ],
   "source": [
    "history = model_13.fit(X_train_scalled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1=ResidualBlock(2,30)\n",
    "model_14 = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    block1,\n",
    "    block1,\n",
    "    block1,\n",
    "    block1,\n",
    "    ResidualBlock(2,30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7863\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5023\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3875\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3543\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3520\n",
      "162/162 [==============================] - 0s 870us/step - loss: 0.4371\n",
      "162/162 [==============================] - 0s 708us/step\n"
     ]
    }
   ],
   "source": [
    "model_14.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model_14.fit(X_train_scalled, y_train, epochs=5)\n",
    "score = model_14.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model_14.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losees and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the following code has two differences with the code in the book:\n",
    "1. It creates a `keras.metrics.Mean()` metric in the constructor and uses it in the `call()` method to track the mean reconstruction loss. Since we only want to do this during training, we add a `training` argument to the `call()` method, and if `training` is `True`, then we update `reconstruction_mean` and we call `self.add_metric()` to ensure it's displayed properly.\n",
    "2. Due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), we must not call `super().build()` inside the `build()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        #super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(5e-2 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7076 - reconstruction_error: 0.8598\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4091 - reconstruction_error: 0.3396\n",
      "162/162 [==============================] - 0s 721us/step\n"
     ]
    }
   ],
   "source": [
    "model_15 = ReconstructingRegressor(1)\n",
    "model_15.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model_15.fit(X_train_scalled, y_train, epochs=2)\n",
    "y_pred = model_15.predict(X_test_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0dba2b93f70ea02af85bf297da8a2cbb84bcde8c4c1992f67259c4cf3550e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
